server:
  port: 8011
  servlet:
    context-path: /kafka

spring:
  kafka:
    # kafka服务器地址
    bootstrap-servers: http://localhost:9020,http://localhost:9021,http://localhost:9022
    producer:
      # 发生错误后，消息重发的次数。
      retries: 0
      #当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。
      batch-size: 16384
      # 设置生产者内存缓冲区的大小。
      buffer-memory: 33554432
      # key/value的序列化
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # acks=0:生产者在成功写入消息之前不会等待任何来自服务器的响应。
      # acks=1:只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
      # acks=all:只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
      acks: 1
    consumer:
       # 指定默认组名
       group-id: consumer-group
       # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
       # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
       # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
       auto-offset-reset: earliest
       # 是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
       enable-auto-commit: true
       # 自动提交的时间间隔
       auto-commit-interval: 20000
       # key/value的反序列化
       key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
       value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      # 设置消费线程数
      concurrency: 3


